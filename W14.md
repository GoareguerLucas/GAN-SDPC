# Résumé de la semaine 14 de stage


## A faire :

- [x]  Mettre à jour l'ordinateur
- [x]  Trouvé un dataset Simpsons
- [x]  Construire un module Dataset torch
- [x]  Nettoyer le dataset Dataset (cf. W10_dataset_dcgan)
- [x]  Trouver un GAN efficace sur le dataset
- [ ] Tunner le GAN jusqu'à avoir un résultats concluant
- [ ] Tester CycleGAN pour transformer des visages humain en Simpsons
- [ ] Prendre en main SDPC
- [ ] Trouver une architecture pour fusionner le GAN et SDPC
- [ ] Evaluer l'intèret de l'architecture
- [ ] Tester BigGan qui promet de bien marcher mais demande beaucoup de ressource : Peut être
- [x] from skimage.color import rgb2hsv
- [x] https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomAffine
- [x] Apprendre à utliser Tensorboard
- [x] Ajout d'un module de scan des paramètre compatible avec tensorboard (cf. current pour plus de détails)
- [x] Ajouter des affichages de résultats plus complets (std, coefficient de variation,..)

## Mise à jour des codes communs

###Utilisation de tensorboard :

1 - Dans le code [Tutoriel](https://www.tensorflow.org/guide/summaries_and_tensorboard) [Doc](https://pytorch.org/docs/stable/tensorboard.html)
2 - Les codes compatibles sauvegardes les données dans un dossier, par défault ./runs/.
3 - Puis la commande : tensorboard --logdir=runs, permet de lancer un serveur pour visualiser ces données durant l'entraînement sur le port 6006.
4 - Connexion sur le port 6006 du GPU depuis le port 16006 de l'ordinateur : ssh -p8012 -L16006:localhost:6006 g14006889@gt-0.luminy.univ-amu.fr
5 - Ouverture d'un navigateur à l'adresse : http://localhost:16006

## Note d'expériences

#### Test lr-esp en 64x64 batchsize=64 epochs=200 
Test grandeur nature du scan des paramètres
Scan des paramètre :
  - lrG
  - lrD
  - eps : Batch normalisation
Une extension de l'expérience à était mener pour explorer plus en profondeur lrG et lrD.
cf. scan_params2.py

__Résultats__ :
  - lrG : 
    Time=1h15m (x2)
  - lrD : 
    Time=1h15m (x2)
		
__Conclusion__ :
  - scan_params2 :
    - :

#### Test b1b2 en 64x64 epochs=200 
Exploration des paramètres 
Scan des paramètre :
  - b1 : [0.1, 0.3, 0.7, 0.9] 
  -b2 : [0.8, 0.9, 0.99]
cf. scan_params.py

__Résultats__ :
  - batch_size : Un B2 trop haut augmente l'instabilité des résultats. La valeur de B1 à peut d'impacte mais il semble qu'une valeurs basse donne de meilleurs résultats
    Time= 
		
__Conclusion__ :
  - :

#### Test noise en 64x64 epochs=200 
Exploration des paramètres 
Scan des paramètre :
  - noise : [0.05, 0.1, 0.15, 0.2]
cf. scan_params.py

Comparer principalement avec : Lr_Esp/lrD5e05lrG0.0005eps0.5/2019-06-28_11.50.3
__Résultats__ :
  - noise : Les courbes montrent des résultats très encouragent mais qui ne ce vérifie pas sur les images. Les losses et les scores ne varie que très peut. L'apprentissage semble ralentie par les bruits.
    Time= 1h15m (x4)
		
__Conclusion__ :
  - Le niveau de bruit à peut d'impacte sur les résultats.
  - Plus le bruits est haut plus les constante sont stable (score/loss) mais de pas grand chose.
  - Avec du bruits ils faudrait tester plus d'epochs.
   
