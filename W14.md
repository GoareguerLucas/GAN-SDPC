# Résumé de la semaine 14 de stage


## A faire :

- [x]  Mettre à jour l'ordinateur
- [x]  Trouvé un dataset Simpsons
- [x]  Construire un module Dataset torch
- [x]  Nettoyer le dataset Dataset (cf. W10_dataset_dcgan)
- [x]  Trouver un GAN efficace sur le dataset
- [ ] Tunner le GAN jusqu'à avoir un résultats concluant
- [ ] Tester CycleGAN pour transformer des visages humain en Simpsons
- [ ] Prendre en main SDPC
- [ ] Trouver une architecture pour fusionner le GAN et SDPC
- [ ] Evaluer l'intèret de l'architecture
- [ ] Tester BigGan qui promet de bien marcher mais demande beaucoup de ressource : Peut être
- [x] from skimage.color import rgb2hsv
- [x] https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomAffine
- [x] Apprendre à utliser Tensorboard
- [x] Ajout d'un module de scan des paramètre compatible avec tensorboard (cf. current pour plus de détails)
- [x] Ajouter des affichages de résultats plus complets (std, coefficient de variation,..)

## Mise à jour des codes communs

 - Ajout d'une option à la fonction scan de utils.py

###Utilisation de tensorboard :

1 - Dans le code [Tutoriel](https://www.tensorflow.org/guide/summaries_and_tensorboard) [Doc](https://pytorch.org/docs/stable/tensorboard.html)
2 - Les codes compatibles sauvegardes les données dans un dossier, par défault ./runs/.
3 - Puis la commande : tensorboard --logdir=runs, permet de lancer un serveur pour visualiser ces données durant l'entraînement sur le port 6006.
4 - Connexion sur le port 6006 du GPU depuis le port 16006 de l'ordinateur : ssh -p8012 -L16006:localhost:6006 g14006889@gt-0.luminy.univ-amu.fr
5 - Ouverture d'un navigateur à l'adresse : http://localhost:16006

## Note d'expériences

#### Test lr-esp en 64x64 batchsize=64 epochs=200 
Test grandeur nature du scan des paramètres
Scan des paramètre :
  - lrG
  - lrD
  - eps : Batch normalisation
Une extension de l'expérience à était mener pour explorer plus en profondeur lrG et lrD.
cf. scan_params2.py

__Résultats__ :
  - lrG : 
    Time=1h15m (x2)
  - lrD : Un lrD trop bas empêche D d'apprendre assez vite pour "comprendre" G.
    Time=1h15m (x2)
		
__Conclusion__ :
  - Le lr influe sur la vitesse d'apprentissage.
  - scan_params2 :
    - Meilleur valeur tester:
      - lrD : 0.00005
      - lrG : 0.0005
  - Il semble que les models qui ce comporte le mieux on un lrD 10x moins grand que le lrG.
  - Question : Est-ce qu'un model qui apprend plus lentement (ex : lr bas) apprend aussi plus longtemps ?

#### Test b1b2 en 64x64 epochs=200 
Exploration des paramètres 
Scan des paramètre :
  - b1 : [0.1, 0.3, 0.7, 0.9] 
  -b2 : [0.8, 0.9, 0.99]
cf. scan_params.py

__Résultats__ :
  - batch_size : Un B2 trop bas augmente l'instabilité des résultats. La valeur de B1 à peut d'impacte mais il semble qu'une valeurs basse donne de meilleurs résultats
    Time= 1h15m (x12)
		
__Conclusion__ :
  - Meilleur valeur tester :
    - b1 : 0.5
    - b2 : 0.999
  - Les résultats sont très difficile à classer, les valeurs par défauts semble être les meilleurs (avec des réserves).

#### Test noise en 64x64 epochs=200 
Exploration des paramètres 
Scan des paramètre :
  - noise : [0.05, 0.1, 0.15, 0.2]
cf. scan_params.py

Comparer principalement avec : Lr_Esp/lrD5e05lrG0.0005eps0.5/2019-06-28_11.50.3
__Résultats__ :
  - noise : Les courbes montrent des résultats très encouragent mais qui ne ce vérifie pas sur les images. Les losses et les scores ne varie que très peut. L'apprentissage semble ralentie par les bruits.
    Time= 1h15m (x4)
  - epoch=600 () :
    Time=
		
__Conclusion__ :
  - Le niveau de bruit à peut d'impacte sur les résultats.
  - Plus le bruits est haut plus les constante sont stable (score/loss) mais de pas grand chose.
  - Avec du bruits ils faudrait tester plus d'epochs.
   
#### Test lr-bas en 64x64 epochs=600 
Un lr-bas donne des résultats moins bon mais il ce pourrait qu'il permette d'apprendre plus longtemps et donc d'obtenir de meilleur résultats
Scan des paramètre :
  - lrG :
  - lrD : 
cf. scan_params.py

Comparer principalement avec : Lr_Esp/
__Résultats__ :
  - lr (board gt-0): 
    Time= 1h15m (x3)
		
__Conclusion__ :
  - 

