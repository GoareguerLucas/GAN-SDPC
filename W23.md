# Résumé de la semaine 23 de stage


## A faire :

- [x]  Mettre à jour l'ordinateur
- [x]  Trouvé un dataset Simpsons
- [x]  Construire un module Dataset torch
- [x]  Nettoyer le dataset Dataset (cf. W10_dataset_dcgan)
- [x]  Trouver un GAN efficace sur le dataset
- [x] Tunner le GAN jusqu'à avoir un résultats concluant
- [ ] Tester CycleGAN pour transformer des visages humain en Simpsons
- [ ] Prendre en main SDPC
- [ ] Trouver une architecture pour fusionner le GAN et SDPC
- [ ] Evaluer l'intèret de l'architecture
- [ ] Tester BigGan qui promet de bien marcher mais demande beaucoup de ressource : Peut être
- [x] Tester une autre représentation pour les images : from skimage.color import rgb2hsv
- [x] Utiliser une méthodes d'augmentation du dataset : https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomAffine
- [x] Apprendre à utliser Tensorboard
- [x] Ajout d'un module de scan des paramètre compatible avec tensorboard (cf. current pour plus de détails)
- [x] Ajouter des affichages de résultats plus complets (std, coefficient de variation,..)
- [x] Création d'un dataset baser sur un espace latent connue [cf. ref](http://datashader.org/topics/strange_attractors.html)
- [x] Comprendre et améliorer l'apprentissage de l'auto-encoders
- [x] Terminer l'expérience sur les espaces latent
- [x] Rapport :
  - [x] Rédaction
  - [x] Références
  - [x] Mise en forme
  - [x] Illustration
  - [x] Description détaillées des architectures
  - [x] Correction
  - [x] Relecture
- [x] Présentation Orale
  - [x] Diapositive
  - [x] Entrainement
- [x] Mettre le FDD sur Kaggle
  - [x] Ajout d'une description
  - [x] Ajout de description de fichier
  - [x] Ajout d'un kernels
- [ ] Construire le package AEGEAN

## Mise à jour des codes communs

Importante modification du loader de dataset.
Une fonction a était crée pour le chargement de FDD et elle renvoie pour chaque images le vecteur de paramètres associer.

### Utilisation de tensorboard :

1. Dans le code [Tutoriel](https://www.tensorflow.org/guide/summaries_and_tensorboard) [Doc](https://pytorch.org/docs/stable/tensorboard.html)
2. Les codes compatibles sauvegardes les données dans un dossier, par défault `./runs/.`
3. Puis la commande : `tensorboard --logdir=runs`, permet de lancer un serveur pour visualiser ces données durant l'entraînement sur le port 6006.
4. Connexion sur le port 6006 du GPU depuis le port 16006 de l'ordinateur : `ssh -p8012 -L16006:localhost:6006 g14006889@gt-0.luminy.univ-amu.fr`
5. Ouverture d'un navigateur à l'adresse : http://localhost:16006

## Note d'expériences

#### Test Detach_SF en 128x128 epochs=200
Comparaison de AAE avec LossEG et LossE.

__Résultats__ :
  - detach : Résultats attendue.
    Time= 16h

__Conclusion__ :
  - Le générateur a appris de façon équivalente  a un DCGAN.
  - L'expérience a était mener sur Simspons Faces, il faut la refaire avec FDD.

![W17_dcgan_MAX](W23_Detach_SF/200.png "MAX")

#### Test Detach_FDD en 128x128 epochs=50
Comparaison de AAE avec LossEG et LossE sur FDD.

__Résultats__ :
  Paramétrage de D et G :
    - Utilisation des paramètres de W17_FDD_dcgan.
    - Résultats de génération acceptable.
    Time = 40m
  Paramétrage de E :
    - Alors que l'apprentissage de G est fixe on constate des variation dans les images générer avec un bruit fixe.
    - Les images reconstruite sont d'une qualité similaire a celle générer mais ne corresponde pas a celles encoder.
    Time = 10m

__Conclusion__ :
  - Le fait d'utiliser un lossE plutôt qu'un lossEG ne permet pas de trouver une correspondances entre les espace latent.

![W23_Detach_FDD](W23_Detach_FDD/train_DG_50.png "Train D et G")
![W23_Detach_FDD](W23_Detach_FDD/FDD_sample.png "Images du dataset avant reconstruction")
![W23_Detach_FDD](W23_Detach_FDD/reconstruct_GEx_50.png "Images du dataset reconstruite par EG")


#### Test G_stride en 128x128 epochs=100
Test de corection du stride de G : 1 => 2

__Résultats__ :
  - Stride2 (gt-0 board): Les images sont constituer de bruits.
    Time= 7h

__Conclusion__ :
  - L'utilisation d'un stride 2 pour le générateur ne fonctione pas.

#### Test Interpol_SF en 128x128 epochs=200
Entrainement et sauvegarde d'un model DCGAN_MAX.
Utilisation du model pour crée des interpolation entre différent personnages des simpsons.

Meilleur model : 2_G.pt

Pour faire des interpolation cyclique :
  - Interpoler entre A et B
  - Puis entre B et C
  - Enfin entre C et A

__Résultats__ :
  - Inter (gt-0 board2): Le model a était entraîner, les images ne sont pas les meilleurs mais devrait suffire. Les 50 dernières epochs sont en mode collapse.
    Time= 18h

__Conclusion__ :
  - Les interpolations dans l'espace latent sont fonctionnelles.
  - La plupart des interpolations passe par des zones de l'espace qui sont composer d'images incohérente.
  - Plusieurs interpolation entre personnages fonctionne correctement.

![W23_Interpol_SF](W23_Interpol_SF/results/inter7/training.gif "Interpolation entre Lisa et Bart")
![W23_Interpol_SF](W23_Interpol_SF/results/inter4/training.gif "Interpolation entre Homer et Lisa")
![W23_Interpol_SF](W23_Interpol_SF/results/inter5/training.gif "Interpolation entre deux version de Homer")

#### Test LSD_FDD en 128x128 epochs=200
Ajout au lossG d'une valeur de correspondance entre les images du dataset et les images générer.
LossG = MSE(FD(v),G(v)) - log(D(G(z)))

Étapes :
  - Renvoie du vecteur v associer a chaque image du dataset (cf. SimpsonsDataset.py)
  - Ajout de la nouvelles phase d'entraînement
  - Paramétrage
  - Comparaison des espaces latent  

__Résultats__ :
  - dcgan (50e): Le générateur fournie de bon résultats notamment autour de 40epochs. On ne constate pas de correspondance entre les espaces latents.  
    Time= 1h
  - dcgan (200e): Après la 40éme epochs le model dégénère complètement et les images sont de moins en moins bonnes. A mesure que le mse_g_loss diminue les images deviennent informe et flou.
    Time= 4h

__Conclusion__ :
  - :

![W23_LSD_FDD](W23_LSD_FDD/40.png "Images générer après 40 epochs")
![W23_LSD_FDD](W23_LSD_FDD/200.png "Images générer après 200 epochs")

#### Test SSIM_FDD en 128x128 epochs=200
Test du loss MS_SSIM sur AAE et LSD.

__Résultats__ :
  - AAE : La reconstruction échoue complètement. Les images sont moins flou qu'avec MSE. Des couleurs incohérentes (noirs, jaune, rouge) apparaissent durant l'entraînement. 
    Time=4h25
  - LSD : Les images générer semble un peut meilleurs que sans l'utilisation de MS_SSIM. Au bout de 200 epochs on perd en diversité dans les images.
    Time= 3h

__Conclusion__ :
  - Le MS_SSIM a des effets divers, il semble donner des résultats moins flou que MSE mais souffre d'autres tares.

![W23_SSIM_FDD](W23_SSIM_FDD/200_lsd.png "Images générer avec MS-SSIM et LSD")
![W23_SSIM_FDD](W23_SSIM_FDD/200_aae.png "Images générer avec MS-SSIM et AAE")
