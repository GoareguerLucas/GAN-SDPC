# Résumé de la semaine 18 de stage


## A faire :

- [x]  Mettre à jour l'ordinateur
- [x]  Trouvé un dataset Simpsons
- [x]  Construire un module Dataset torch
- [x]  Nettoyer le dataset Dataset (cf. W10_dataset_dcgan)
- [x]  Trouver un GAN efficace sur le dataset
- [ ] Tunner le GAN jusqu'à avoir un résultats concluant
- [ ] Tester CycleGAN pour transformer des visages humain en Simpsons
- [ ] Prendre en main SDPC
- [ ] Trouver une architecture pour fusionner le GAN et SDPC
- [ ] Evaluer l'intèret de l'architecture
- [ ] Tester BigGan qui promet de bien marcher mais demande beaucoup de ressource : Peut être
- [x] from skimage.color import rgb2hsv
- [x] https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomAffine
- [x] Apprendre à utliser Tensorboard
- [x] Ajout d'un module de scan des paramètre compatible avec tensorboard (cf. current pour plus de détails)
- [x] Ajouter des affichages de résultats plus complets (std, coefficient de variation,..)
- [x] Création d'un dataset baser sur un espace latent connue [cf. ref](http://datashader.org/topics/strange_attractors.html)
- [ ] Comprendre et améliorer l'apprentissage de l'auto-encoders 

## Mise à jour des codes communs

###Utilisation de tensorboard :

1 - Dans le code [Tutoriel](https://www.tensorflow.org/guide/summaries_and_tensorboard) [Doc](https://pytorch.org/docs/stable/tensorboard.html)
2 - Les codes compatibles sauvegardes les données dans un dossier, par défault ./runs/.
3 - Puis la commande : tensorboard --logdir=runs, permet de lancer un serveur pour visualiser ces données durant l'entraînement sur le port 6006.
4 - Connexion sur le port 6006 du GPU depuis le port 16006 de l'ordinateur : ssh -p8012 -L16006:localhost:6006 g14006889@gt-0.luminy.univ-amu.fr
5 - Ouverture d'un navigateur à l'adresse : http://localhost:16006

## Note d'expériences

#### Test FDD_cgan en 64x64 epochs=200
Mise en pratique du Conditionnal DCGAN sur le datatset FDD
Objectif : Déterminer si le CGAN permet de meilleur résultats 

__Résultats__ :
  - cgan : 
    Time= 
		
__Conclusion__ :
  - :

#### Test FDD_interpol en 128x128 epochs=200
Comparaison des espace latent connus et générer
Objectif : Déterminer si le GAN construit un espace latent proche de celui d'origine.
Méthodes : 
  - Calculer toutes les images entre deux images grâce aux formules FractalDream.
  - Utiliser les coordonnées de ces images et le générateur pour générer des images.
  - Comparer les images calculer et générer
  
Paramétrage en cours (board gt-2)
  
__Résultats__ :
  - dcgan : Il semble que l'encoder ne soit pas très efficace.
    Time= 1h30m
		
__Conclusion__ :
  - Il faudra ce concentrer sur l'amélioration du processus d'encodage/décodage.

#### Test AutoEncoder en 128x128 epochs=50
L'auto-encoders montre des résultats peut concluant (cf. FDD_interpol).
Objectif : Améliorer l'apprentissage de l'Auto-Encoders

Méthodes :
  - 1 [x] Pré apprentissage de l'AE
  - 2 [ ] Paramétrages plus fin de l'encoder 
    - scan_params.py
      - b1 : 0.5
      - eps : 0.05
      - lrelu : 0.02
    - scan_params2.1.py
    - scan_params2.2.py
    - scan_params3.py
    - scan_params4.py (board gt-0)
    - scan_params5.py (board gt-0)
  - 3 [x] Retrait de l'apprentissage par AE pour G : On aura une correspondance des espace latent sans "pollution" des apprentissage.
  
__Résultats__ :
  - ae : 
    - L'AE seul fonctionne correctement, les images produites sont relativement proches des images d'entrées.
    - Un pré apprentissage n'aide pas l'apprentissage adversaire qui suis. Il le rend même plus difficile.
    - Il semble que l'asymétrie entre l'entraînement de E et celui de G (qui est ensuite entraîner de manière adversaire) fausse complètement l'idée d'AAE.
    - Le retrait de l'apprentissage de AE pour G n'est pas fonctionnel. 
    Time= Varriable
		
__Conclusion__ :
  - Meilleur valeur tester :
    - lrG : 1e05
    - lrD : 0.0001
    - lrE : 0.001
    - b1 : 0.7
    - eps : 0/0.1
    - lrelu : 
