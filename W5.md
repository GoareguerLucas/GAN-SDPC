# Résumé de la semaine 5 de stage


## A faire :

- [x]  Mettre à jour l'ordinateur
- [x]  Trouvé un dataset Simpsons
- [x]  Construire un module Dataset torch
- [x]  Trouver un GAN efficace sur le dataset
- [ ] Tunner le GAN jusqu'à avoir un résultats concluant
- [ ] Tester CycleGAN pour transformer des visages humain en Simpsons
- [ ] Prendre en main SDPC
- [ ] Trouver une architecture pour fusionner le GAN et SDPC
- [ ] Evaluer l'intèret de l'architecture
- [ ] Tester BigGan qui promet de bien marcher mais demande beaucoup de ressource : Peut être

## Note d'expériences

##### Test init en 32x32 batchsize=32 epochs=1000
Initialisation des poids différente [ref](https://github.com/carpedm20/BEGAN-pytorch/issues/7)
Began : decay0.9_evry_Mstall  lr=0.0001 gamma=0.5
Dcgan : decay0.1_evry_1000 lr=0.0004

__Résultats__ :
  - BEGAN (gt-2): On optient des images plus convaincante qu'avec les précédents BEGAN. Le mode collapse apparait plus tard (240). Les courbes montrent un diminution progressive de l'apprentissage.
		Time=5h45
  - DCGAN (gt-0): On ne constate pas de difference particulière que ce soit au niveau des images ou des courbes, comparer à W4_current_dcgan.
		Time=2h25
		
__Conclusion__ :
  - BEGAN : L'initialisation à permis un bien meilleurs départ et à éviter le mode collapse dès le commencement. Il va falloir jouer sur d'autre paramètres pour maintenir l'apprentissage sur la durré. 
  - DCGAN : Aucun changement

![W5_began final](W5_init_began/final.png "BEGAN")


##### Test ABEGAN en 32x32 batchsize=32 epochs=1000 decay0.5_evry_Mstall  lr=0.0001 gamma=0.5
Asymètrique BEGAN

__Résultats__ :
  - BEGAN (gt-2): 
		Time=
		
__Conclusion__ :
  - :
  
##### Test ReLU en 32x32 batchsize=32 epochs=1000 decay0.9_evry_Mstall  lr=0.0001 gamma=0.5
Remplacement des non-linéarité ELU par ReLU. ReLU est plus standard alors si ELU n'a pas d'effet particulier il vaudra mieux utiliser le standard.

__Résultats__ :
  - BEGAN (gt-2): 
		Time=
		
__Conclusion__ :
  - :

Next : Gamma bas pour éviter mode collapse.
