# Résumé de la semaine 10 de stage


## A faire :

- [x]  Mettre à jour l'ordinateur
- [x]  Trouvé un dataset Simpsons
- [x]  Construire un module Dataset torch
- [x]  Trouver un GAN efficace sur le dataset
- [ ] Tunner le GAN jusqu'à avoir un résultats concluant
- [ ] Tester CycleGAN pour transformer des visages humain en Simpsons
- [ ] Prendre en main SDPC
- [ ] Trouver une architecture pour fusionner le GAN et SDPC
- [ ] Evaluer l'intèret de l'architecture
- [ ] Tester BigGan qui promet de bien marcher mais demande beaucoup de ressource : Peut être
- [x] from skimage.color import rgb2hsv
- [ ] https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomAffine

## Note d'expériences

#### Test Lying en 64x64 batchsize=64 epochs=300 t=6
HRF et noise (pour D(x) et D(G(z))) pour améliorer la stabilité 
Introduire des images réels+noise dans les batch d'image générer (Négatif).
Introduire les meilleurs images générer dans les batchs réels (Positif).

__Résultats__ :
  - Negatif : Les courbes de scores sont plus smooth (la pente est moins prononcer) et D prend l'avantage moins vite. Le lossD diminue aussi moins vite.
		Time=1h45
  - Positif : Les courbes sont très proche des expériences précédentes (cf. W8_HRF) à part un pics sur la fin durant lequel D ne fait plus d'erreur.
		Time=2h25
		
__Conclusion__ :
  - D prend l'avantage moins vite avec Négatif.
  - Les résultats de Négatifs sont meilleurs que ceux de Positifs.
  - D devient vite exigent et transmet cette exigence à G via lossG ou bien D est perdue par les images trop proche du réels et est ralenti dans sont apprentissage.

#### Test Affine en 64x64 batchsize=64 epochs=200 
Utilisation de (RandomAffine)[https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomAffine] pour augmenter le dataset.
Rotate : Ajout d'une rotation aléatoire entre 
Scale : Ajout d'un zoom aléatoire entre 
Both : Ajout d'une rotation et d'un zoom aléatoire entre 
Hypothèse 1 : Les images du dataset contiennent beaucoup de détails dans le fonds, une rotation pourrait permettre de "estomper".
Hypothèse 2 : Certaine images contiennent des visage très petit par rapport au décors, cela pousse le modèle à apprendre les fonds. Un zoom aléatoire pourra "estomper" cet effet. 

__Résultats__ :
  - Rotate (gt-0 dcgan): 
		Time=
  - Scale : 
		Time=
  - Both : 
		Time=
		
__Conclusion__ :
  - D prend l'avantage moins vite avec Négatif.
  - Les résultats de Négatifs sont meilleurs que ceux de Positifs.
  - D devient vite exigent et transmet cette exigence à G via lossG ou bien D est perdue par les images trop proche du réels et est ralenti dans sont apprentissage.


