# Résumé de la semaine 13 de stage


## A faire :

- [x]  Mettre à jour l'ordinateur
- [x]  Trouvé un dataset Simpsons
- [x]  Construire un module Dataset torch
- [x]  Nettoyer le dataset Dataset (cf. W10_dataset_dcgan)
- [x]  Trouver un GAN efficace sur le dataset
- [ ] Tunner le GAN jusqu'à avoir un résultats concluant
- [ ] Tester CycleGAN pour transformer des visages humain en Simpsons
- [ ] Prendre en main SDPC
- [ ] Trouver une architecture pour fusionner le GAN et SDPC
- [ ] Evaluer l'intèret de l'architecture
- [ ] Tester BigGan qui promet de bien marcher mais demande beaucoup de ressource : Peut être
- [x] from skimage.color import rgb2hsv
- [x] https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomAffine
- [x] Apprendre à utliser Tensorboard
- [x] Ajout d'un module de scan des paramètre compatible avec tensorboard (cf. current pour plus de détails)
- [x] Ajouter des affichages de résultats plus complets (std, coefficient de variation,..)

## Mise à jour des codes communs

  - Ajout d'une fonction scan dans utils.py qui permet de gérer facilement le scan des paramètres (cf. current pour plus de détails).
  - Les fonctions de plots qui était dans utils.py on était déplacer vers plot.py.

###Utilisation de tensorboard :

1 - Dans le code [Tutoriel](https://www.tensorflow.org/guide/summaries_and_tensorboard) [Doc](https://pytorch.org/docs/stable/tensorboard.html)
2 - Les codes compatibles sauvegardes les données dans un dossier, par défault ./runs/.
3 - Puis la commande : tensorboard --logdir=runs, permet de lancer un serveur pour visualiser ces données durant l'entraînement sur le port 6006.
4 - Connexion sur le port 6006 du GPU depuis le port 16006 de l'ordinateur : ssh -p8012 -L16006:localhost:6006 g14006889@gt-0.luminy.univ-amu.fr
5 - Ouverture d'un navigateur à l'adresse : http://localhost:16006

## Note d'expériences

#### Test Current en 64x64 batchsize=64 epochs=200 
Nouvelles base avec passage complet à tensorboard et ajout d'un scan des paramètres.

L'usage du scan des paramètres à était rendu le plus simple possible.
Le code ce trouve dans la fonction scan de utils.py.
Il est nécessaires de lire W13_current_dcgan/scan_params.py pour bien comprendre l'usage.

__Résultats__ :
  - DCGAN : Cette version est un test pour développer de nouvelles technique, les résultats ne sont pas commenter 
    Time=
		
__Conclusion__ :
  - Tensorboard est maintenant l'outil unique de visualisation des résultats.
  - L'outil de scan des paramètres fonctionne correctement et est compatible avec tensorboard.
  - Cette version est une base d'outil et d'usage qui devrait accélérer le paramétrage des modèles.
  - Tensorboard est vraiment efficace, facile à prendre en mains et pratique pour comparer de nombreux résultats. 
  - VERSION COURANTE 
  
#### Test lr-esp en 64x64 batchsize=64 epochs=200 
Test grandeur nature du scan des paramètres
Scan des paramètre :
  - lrG
  - lrD
  - eps : Batch normalisation
cf. scan_params.py
Une extension de l'expérience à ensuite était mener pour explorer plus en profondeur lrG et lrD.
cf. scan_params2.py

__Résultats__ :
  - lrG : Si lrG est trop haut G apprend trop vite et D stop rapidement sont apprentissage donc G ne peut plus apprendre et tout s'arrête.
    Time=1h15m (x4)
  - lrD : Avec un lrD plus faible le lossD continue de diminuer tout le long, le lossG augmente moins haut et moins vite et les scores sont plus proche de 0.5 et s'en éloignent moins vite.
    Time=1h15m (x4)
  - eps : Avec un valeur de 0.5 l'apprentissage est plus rapide et les images "semble" meilleur que sans BN.
    Time=1h15m (x4)
		
__Conclusion__ :
  - scan_params :
    - Bug : Les images enregistrer n'ont pas était normaliser avant l'enregistrement, elle ne correspondes pas exactement à la réalité.
    - Les commentaires sur les images sont sujets au bug de normalisation
    - lrG : Trop haut G devient trop bon pour D. Meilleurs valeurs tester : 0.0001. 
    - lrD : Choisir une valeur faible. Meilleurs valeurs tester : 0.00001.
    - eps : Bénéfice certain. Apprentissage accélérer. Meilleurs valeurs tester : 0.5. 
  - scan_params2 :
    - :

#### Test latentDim en 64x64 batchsize=64 epochs=200 
Exploration des paramètres 
Scan des paramètre :
  - latent_dim : [50, 100, 150, 200], on pourras regarder runs/Lr_Esp/lrG0.0001lrD1e05eps0.5/ pour une version avec latent_dim==100
cf. scan_params.py

__Résultats__ :
  - latent_dim : 
    Time= 1h15(4x)
		
__Conclusion__ :
  - Données perdues
  - Les résultats de la latentDim 100 sons copier de W13_lr-esp_dcgan et les images n'y était pas normaliser.
  - La latentDim ne semble pas avoir d'impact sur les résultats où sur les images.
  - Il semble que 50 soit une valeurs déjà largement suffisante pour stocker l'information d'images de taille 64.
  
#### Test batchsize en 64x64 epochs=200 
Exploration des paramètres 
Scan des paramètre :
  - batch_size : [8, 16, 32, 64], on pourras regarder runs/Lr_Esp/lrG0.0001lrD1e05eps0.5/ pour une version avec batch_size==64
cf. scan_params.py

__Résultats__ :
  - batch_size : Les courbes sont difficile à comparer car avec un batchsize plus faible le nombre d'iteration augmente. On constate un collapse avec une valeurs de 8. Les images sont de meilleurs qualités avec un batch plus petit.
    Time= 2h5m - 2h10 - 1h30 - 1h15
		
__Conclusion__ :
  - Données perdues
  - Les résultats de la batchsize 64 sons copier de W13_lr-esp_dcgan et les images n'y était pas normaliser.
  - Plus le batch size est faible plus le temps est long.
  - Plus les batch sont petit moins on a de les informations de gradients sont diluer et plus on apprend.
  - C'est un compromis nombre d'epochs/batchSize.
  - Il semble qu'un batchSize trop faible pousse au collapse.
  - Meilleurs valeurs tester : 16.

#### Test b1b2 en 64x64 epochs=200 
Exploration des paramètres 
Scan des paramètre :
  - b1 : [0.1, 0.3, 0.7, 0.9] 
  -b2 : [0.8, 0.9, 0.99]
cf. scan_params.py

__Résultats__ :
  - batch_size :
    Time= 
		
__Conclusion__ :
  - :

#### Test noise en 64x64 epochs=200 
Exploration des paramètres 
Scan des paramètre :
  - noise : [0.05, 0.1, 0.15, 0.2]
cf. scan_params.py

__Résultats__ :
  - batch_size :
    Time= 
		
__Conclusion__ :
  - :
