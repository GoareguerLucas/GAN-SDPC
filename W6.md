# Résumé de la semaine 6 de stage


## A faire :

- [x]  Mettre à jour l'ordinateur
- [x]  Trouvé un dataset Simpsons
- [x]  Construire un module Dataset torch
- [x]  Trouver un GAN efficace sur le dataset
- [ ] Tunner le GAN jusqu'à avoir un résultats concluant
- [ ] Tester CycleGAN pour transformer des visages humain en Simpsons
- [ ] Prendre en main SDPC
- [ ] Trouver une architecture pour fusionner le GAN et SDPC
- [ ] Evaluer l'intèret de l'architecture
- [ ] Tester BigGan qui promet de bien marcher mais demande beaucoup de ressource : Peut être

## Note d'expériences
  
##### Test Dropout en 32x32 batchsize=32 epochs=1000 lr=0.0004
Poursuite des test de la semaine prècédentes sur le dropout.

__Résultats__ :
  - DCGAN 0.75: Les courbes montre que D n'apprend plus. Difficile de savoir à l'oeil si les images s'amèliore une fois que loss_D commence à stagner.
		Time=2h30m
  - DCGAN 0.5: L'apprentissage ralentie beaucoup après 300epochs mais les images sont meilleur qu'avec le dropout à 0.75 (on vois plus de visage et moins d'artefacts)
		Time=2h20
		
__Conclusion__ :
  - Le modèle semble avoir converger (scores proche de 0.5) pour la première fois !!
  - Le dropout à un impacte sur la vitesse et/ou la capacité du modèle à converger. 
  - Un dropout trop bas (0.0) crée l'apparition de bruit et trop haut (0.75) il empêche l'apparition des visages.

![W6_DCGAN scores](W6_dropout_dcgan/0.5/scores.png "DCGAN Scores Convergeance")

##### Test Treshold en 32x32 batchsize=32 epochs=300 lr=0.0004
G est conforter pour ces création qui trompe le mieux D et mais il est punnis pour ces mauvaises céations. 

__Résultats__ :
  - DCGAN : L'apprentissage ne c'est pas dutout produit. Les images sont en nuances de violet.
		Time=35m
		
__Conclusion__ :
  - La méthodes est à revoir et le code à vérifier .
  
##### Test current en 64x64 batchsize=32 epochs=5000 lr=0.0004 eps=0.05
D train avant G
Deux batch distinct (fack et real) pour train D
BCElogits
Retrait de LS
Retrait du dropout
Méthode de sampling en mode eval avec fixed noise

__Résultats__ :
  - DCGAN (gt-0 dcgan): Les images sont moins belles qu'avec W5_init_dcgan, cela vient surement de BCElogits ou de l'absence de dropout. On constate (sur les courbe et les images) un point (440 environ) à partir duquel G dé-apprend complètement.
		Time=3h 
		
__Conclusion__ :
  - Ce modèl corrige une part des erreur d'implémentation faite jusqu'ici sans modification majeurs des résultats.
  - C'est une nouvelle base de travail.
  
##### Test points en 32x32 batchsize=32 epochs=50 lr=0.0004
Hypothèse : Les points noirs constater sur les images sont du au dropout. La génération des images durant l'entrainement est affecter par le dropout.
Pour verrifier ceci on va générer les images de la manière habituel puis en passant le modèle en mode eval. 

__Résultats__ :
  - DCGAN : Rien de particulier à signaler, l'entrainement est normale et les courbes aussi.
		Time=6m
		
__Conclusion__ :
  - On constate une légère difference entre les images générer en mode train et en mode eval. Cette difference n'est pas au niveau des points noirs mais les images en mode éval sont plus claire.
  - La difference vient probablement de la batchNormalization
  
##### Test large en 32x32 batchsize=32 epochs=300 lrG=0.0004 lrD=0.00004 eps=0.00005
La plupart des modèles vues sur le net on des réseaux bien plus gros que ceux utiliser jusqu'alors.
Hypothèse 1: Le réseau actuel n'a pas la capacité pour apprendre au delà de quelques epochs
Test avec plus de filtres et de couches pour G et D [Inspiration principal](https://github.com/gsurma/image_generator)

Hypothèse 2: Le bruit qui sert à générer les samples est fixer une fois avant l'entrainment et ne bouge plus ensuite. On s'attend donc à observer une image qui évolue par étape en gardant une forme général.

__Résultats__ :
  - DCGAN (conv2d+Upsampl)(k=3,s=1,p=1): Les résultats sont similaire à ceux obtenues jusqu'ici. Mode collapse 
		Time=45m
  - DCGAN (conv2d+Upsampl)(k=5,s=1,p=2): Les résultats sont proche de ceux obtenues avec (k=3,s=1,p=1). Le noyau de taille 5 réduit en parti les "bruits". Mode collapse
		Time=1h
  - DCGAN (convTranspose2d)(k=4,s=2,p=1): Les meilleurs images pour le moment !! Pas de mode collapse. L'apprentissage semble pouvoir continuer au delà de 300 epochs
		Time=30m
		
__Conclusion__ :
  - Il semble que convTranspose2d permettent d'éviter le mode collapse.
  - Hypothèse 2 : On constate éfféctivement une même image qui ce précise au cour de l'entrainement avec (convTranspose2d). En revanche ce n'est absolument pas le cas avec (conv2d+Upsampl).
  - Hypothèse 1 : Il semble au vues des courbes que le réseaux n'apprend pas plus longtemps.

##### Test Mini en 32x32 batchsize=32 epochs=300 lrG=0.0004 lrD=0.00004 eps=0.00005
Au vus des résultats de W5_mini_dcgan kernel 
Un générateur très simplifier, pour DCGAN, avec deux couche de convTranspose2d.

__Résultats__ :
  - DCGAN (gt-0 dcgan): 
		Time=
		
__Conclusion__ :
  - :

##### Test 128 en 128x128 batchsize=32 epochs=1000 lrG=0.0004 lrD=0.00004 eps=0.00005
Au vus des résultats de W6_large_dcgan et W5_mini_dcgan 
Un générateur très simplifier, pour DCGAN, avec deux couche de convTranspose2d.
Objectif : dessiner des formes simples, visage et eventuellement oeil.

__Résultats__ :
  - DCGAN : 
		Time=
		
__Conclusion__ :
  - :
